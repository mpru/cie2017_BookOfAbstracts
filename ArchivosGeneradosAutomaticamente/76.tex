\A
{SELECCIÓN DE ATRIBUTOS MEDIANTE ENTROPÍA CONDICIONAL PARA DIFERENTES NIVELES DE INCERTIDUMBRE}
{\Presenting{MARÍA DEL CARMEN ROMERO}$^1$\index{ROMERO, M} y ALEJANDRO CLAUSSE$^2$\index{CLAUSSE, A}}
{\Afilliation{$^1$FACULTAD DE CIENCIAS ECONÓMICAS, UNIVERSIDAD NACIONAL DEL CENTRO DE LA PROVINCIA DE BUENOS AIRES}
\Afilliation{$^2$PLADEMA, FACULTAD DE CIENCIAS EXACTAS, UNIVERSIDAD NACIONAL DEL CENTRO DE LA PROVINCIA DE BUENOS AIRES}
\\\Email{mariadelc.romero@gmail.com}}
{selección de atributos; clasificación supervisada; entropía; simulación} 
 {Otras aplicaciones} 
 {Minería de datos} 
 {76} 
 {171-1}
{La clasificación supervisada y la selección de atributos diferenciales tienen múltiples aplicaciones; en particular en contextos de alta dimensionalidad, debido al crecimiento de las bases de datos (no sólo por la cantidad de observaciones sino también de atributos, y por los escenarios con mayor cantidad de atributos que de observaciones). En Romero, Di Rienzo y Clausse (2013) se presentó un método que usa la entropía condicional para seleccionar atributos que pueden considerarse diferenciales en la determinación de grupos (dados por un atributo de clasificación) y en Romero y Clausse (2016) se analizó el método para diferente cantidad de observaciones y de atributos, considerando distintos niveles de dependencia. La entropía condicional se define como la cantidad media de incertidumbre que tiene un atributo (en este caso, el que determina el grupo) conociendo la información que aporta otro. Si la entropía del grupo disminuye por el conocimiento de algún atributo, éste es relevante para la distinción entre grupos. Una mejora al método propuesto consiste en recomendar un determinado subconjunto de atributos diferenciales considerando la máxima incertidumbre que se esté dispuesto a tolerar (en términos de entropía condicional). En general, es esperable que ante altos niveles de incertidumbre, unos pocos atributos sean suficientes para distinguir entre grupos, mientras que ante menores niveles, se requiera una cantidad mayor. En este trabajo, se aborda la problemática de detectar estos diferentes puntos de corte, en los cuales se modifica la cantidad de atributos diferenciales a considerar. El objetivo es explorar preliminarmente distintos indicadores presentes en los conjuntos de datos que puedan ser utilizados para “detectar” estos puntos de corte. Entre los principales resultados, se encuentra que la entropía de la cantidad de atributos seleccionados es un indicador pertinente y que presenta un buen comportamiento incluso en contextos con una baja cantidad de observaciones. Este indicador se calcula realizando permutaciones sobre el conjunto de datos original. Se trabajó con escenarios de atributos cualitativos, en particular binarios, en los cuales la selección de diferente cantidad de atributos diferenciales conduce a distintos niveles de incertidumbre en la determinación del grupo. Se utilizó el software R y los diferentes escenarios fueron generados mediante simulación.}
